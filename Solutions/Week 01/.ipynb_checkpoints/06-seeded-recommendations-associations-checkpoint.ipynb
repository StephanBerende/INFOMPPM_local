{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“š Recommendations based on Frequently Reviewed Together (association rules)\n",
    "For the final segment of this assignment, refer to section 5.4 of the _Practical Recommender Systems_ book (pages 113-127). After reading, download the code provided by the book and focus on the `association_rules_calculator.py` in the `builder` directory. Your task is to adapt this code for use in this notebook, translating its steps into a format suitable for our environment. Here's a simplified outline based on the source code:\n",
    "\n",
    "The steps found in the source code are:\n",
    "1. Load the data\n",
    "2. Generate transactions or, in our case reviews\n",
    "3. Calculate the Support Confidence\n",
    "4. Save the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data\n",
    "Instead of using a database, load your `.csv` files into a dataframe. Select the data necessary for identifying which user reviewed which books.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/BX-Book-Ratings-Subset.csv', sep=';', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>6575</td>\n",
       "      <td>006000438X</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>6575</td>\n",
       "      <td>0060198133</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>6575</td>\n",
       "      <td>0060502258</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>6575</td>\n",
       "      <td>0060926317</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>6575</td>\n",
       "      <td>0060928336</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38796</th>\n",
       "      <td>258534</td>\n",
       "      <td>074343627X</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38797</th>\n",
       "      <td>258534</td>\n",
       "      <td>0743437802</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38798</th>\n",
       "      <td>258534</td>\n",
       "      <td>0805062971</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38799</th>\n",
       "      <td>258534</td>\n",
       "      <td>0805063897</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38800</th>\n",
       "      <td>258534</td>\n",
       "      <td>1400033543</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1779 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       User-ID        ISBN  Book-Rating\n",
       "840       6575  006000438X            9\n",
       "841       6575  0060198133            8\n",
       "842       6575  0060502258            8\n",
       "843       6575  0060926317            2\n",
       "844       6575  0060928336            8\n",
       "...        ...         ...          ...\n",
       "38796   258534  074343627X            9\n",
       "38797   258534  0743437802            9\n",
       "38798   258534  0805062971            7\n",
       "38799   258534  0805063897            7\n",
       "38800   258534  1400033543            7\n",
       "\n",
       "[1779 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users = df.groupby('User-ID')['ISBN'].count().reset_index(name='counts')\n",
    "users = list(df_users[(df_users['counts'] > 100) & (df_users['counts'] < 200)]['User-ID'])\n",
    "\n",
    "df.loc[df['User-ID'].isin(users)]\n",
    "\n",
    "#df[df['User-ID'] == 104636]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generating the reviews\n",
    "In this context, transactions are the reviews. You need to compile a list of lists, where each inner list contains reviews that are related, similar to how shopping lists are grouped in the example: `[['eggs','milk','bread'], ['bacon', 'bread'], [...], [...]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = df.groupby('User-ID')['ISBN'].apply(list)\n",
    "reviewed = df_reviews.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Calculate the Support Confidence\n",
    "This requires some puzzling, but looking at the source code will give you a clear idea. You can reuse the subroutines in the source code and pass along the list containing the reviews belonging together. Play around with the _minimum support_ parameter. Too strict will result in fewer associations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code originated from the book Practical Recommender System. \n",
    "# Some minor tweaks to make it work with the current dataset.\n",
    "\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from datetime import datetime\n",
    "\n",
    "def calculate_itemsets_one(reviewed, min_sup=0.01):\n",
    "    N = len(reviewed)\n",
    "    print(N)\n",
    "    temp = defaultdict(int)\n",
    "    one_itemsets = dict()\n",
    "\n",
    "    for items in reviewed:\n",
    "        for item in items:\n",
    "            inx = frozenset({item})\n",
    "            temp[inx] += 1\n",
    "\n",
    "    print(\"temp:\")\n",
    "    i = 0\n",
    "    # remove all items that is not supported.\n",
    "    for key, itemset in temp.items():\n",
    "        #print(f\"{key}, {itemset}, {min_sup}, {min_sup * N}\")\n",
    "        if itemset > min_sup * N:\n",
    "            i = i + 1\n",
    "            one_itemsets[key] = itemset\n",
    "    print(i)\n",
    "    return one_itemsets\n",
    "\n",
    "def calculate_itemsets_two(reviewed, one_itemsets):\n",
    "    two_itemsets = defaultdict(int)\n",
    "\n",
    "    for items in reviewed:\n",
    "        items = list(set(items))  # remove duplications\n",
    "\n",
    "        if (len(items) > 2):\n",
    "            for perm in combinations(items, 2):\n",
    "                if has_support(perm, one_itemsets):\n",
    "                    two_itemsets[frozenset(perm)] += 1\n",
    "        elif len(items) == 2:\n",
    "            if has_support(items, one_itemsets):\n",
    "                two_itemsets[frozenset(items)] += 1\n",
    "    return two_itemsets\n",
    "\n",
    "def calculate_association_rules(one_itemsets, two_itemsets, N):\n",
    "    timestamp = datetime.now()\n",
    "\n",
    "    rules = []\n",
    "    for source, source_freq in one_itemsets.items():\n",
    "        for key, group_freq in two_itemsets.items():\n",
    "            if source.issubset(key):\n",
    "                target = key.difference(source)\n",
    "                support = group_freq / N\n",
    "                confidence = group_freq / source_freq\n",
    "                rules.append((timestamp, next(iter(source)), next(iter(target)),\n",
    "                              confidence, support))\n",
    "    return rules\n",
    "\n",
    "def has_support(perm, one_itemsets):\n",
    "  return frozenset({perm[0]}) in one_itemsets and \\\n",
    "    frozenset({perm[1]}) in one_itemsets\n",
    "\n",
    "min_sup = 0.01\n",
    "N = len(reviewed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1834\n",
      "temp:\n",
      "724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "353926"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_itemsets = calculate_itemsets_one(reviewed, min_sup)\n",
    "two_itemsets = calculate_itemsets_two(reviewed, one_itemsets)\n",
    "rules = calculate_association_rules(one_itemsets, two_itemsets, N)\n",
    "\n",
    "# check how many associations are made\n",
    "len(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Save the results\n",
    "Create a dataframe for the results of step 3. In order to make it work with the current app please make sure the columns are `source;target;support;confidence`. Save the recommendations as `recommendations-seeded-associations.csv` and replace the file in the app directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "associations = []\n",
    "\n",
    "# iterate through results and create data structure containing the results\n",
    "for rule in rules:\n",
    "  association = {\n",
    "    'source':str(rule[1]),\n",
    "    'target':str(rule[2]),\n",
    "    'confidence':rule[3],\n",
    "    'support':rule[4]\n",
    "  }\n",
    "  # append to list\n",
    "  associations.append(association)\n",
    "\n",
    "# create dataframe\n",
    "df_associations = pd.DataFrame(associations) \n",
    "\n",
    "df_associations.to_csv('recommendations-seeded-associations.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37c10f95d263926787ebf1d430d11186fc6b9bac835b8518e0b5006ed24f0c36"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
