{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with NER\n",
    "In this Notebook you will use basic NER to extract possible interesting metadata. We will use the movies dataset from IMDb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E053] Could not read config file from C:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\en_core_web_sm\\en_core_web_sm-2.2.0\\config.cfg",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m displacy\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# load spacy model. Alternatively you can use en_core_web_lg\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# load the data\u001b[39;00m\n\u001b[0;32m     11\u001b[0m df_movies \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/imdb.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m     28\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     35\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[0;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m util\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m     52\u001b[0m         name,\n\u001b[0;32m     53\u001b[0m         vocab\u001b[38;5;241m=\u001b[39mvocab,\n\u001b[0;32m     54\u001b[0m         disable\u001b[38;5;241m=\u001b[39mdisable,\n\u001b[0;32m     55\u001b[0m         enable\u001b[38;5;241m=\u001b[39menable,\n\u001b[0;32m     56\u001b[0m         exclude\u001b[38;5;241m=\u001b[39mexclude,\n\u001b[0;32m     57\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m     58\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\util.py:465\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_lang_class(name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblank:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))()\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_package(name):  \u001b[38;5;66;03m# installed as package\u001b[39;00m\n\u001b[1;32m--> 465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m load_model_from_package(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Path(name)\u001b[38;5;241m.\u001b[39mexists():  \u001b[38;5;66;03m# path to model data directory\u001b[39;00m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m load_model_from_path(Path(name), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\util.py:501\u001b[0m, in \u001b[0;36mload_model_from_package\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load a model from an installed package.\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \n\u001b[0;32m    486\u001b[0m \u001b[38;5;124;03mname (str): The package name.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;124;03mRETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(name)\n\u001b[1;32m--> 501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mload(vocab\u001b[38;5;241m=\u001b[39mvocab, disable\u001b[38;5;241m=\u001b[39mdisable, enable\u001b[38;5;241m=\u001b[39menable, exclude\u001b[38;5;241m=\u001b[39mexclude, config\u001b[38;5;241m=\u001b[39mconfig)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\en_core_web_sm\\__init__.py:12\u001b[0m, in \u001b[0;36mload\u001b[1;34m(**overrides)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moverrides):\n\u001b[1;32m---> 12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m load_model_from_init_py(\u001b[38;5;18m__file__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moverrides)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\util.py:682\u001b[0m, in \u001b[0;36mload_model_from_init_py\u001b[1;34m(init_file, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m    681\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE052\u001b[38;5;241m.\u001b[39mformat(path\u001b[38;5;241m=\u001b[39mdata_path))\n\u001b[1;32m--> 682\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m load_model_from_path(\n\u001b[0;32m    683\u001b[0m     data_path,\n\u001b[0;32m    684\u001b[0m     vocab\u001b[38;5;241m=\u001b[39mvocab,\n\u001b[0;32m    685\u001b[0m     meta\u001b[38;5;241m=\u001b[39mmeta,\n\u001b[0;32m    686\u001b[0m     disable\u001b[38;5;241m=\u001b[39mdisable,\n\u001b[0;32m    687\u001b[0m     enable\u001b[38;5;241m=\u001b[39menable,\n\u001b[0;32m    688\u001b[0m     exclude\u001b[38;5;241m=\u001b[39mexclude,\n\u001b[0;32m    689\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m    690\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\util.py:538\u001b[0m, in \u001b[0;36mload_model_from_path\u001b[1;34m(model_path, meta, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    536\u001b[0m config_path \u001b[38;5;241m=\u001b[39m model_path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig.cfg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    537\u001b[0m overrides \u001b[38;5;241m=\u001b[39m dict_to_dot(config, for_overrides\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 538\u001b[0m config \u001b[38;5;241m=\u001b[39m load_config(config_path, overrides\u001b[38;5;241m=\u001b[39moverrides)\n\u001b[0;32m    539\u001b[0m nlp \u001b[38;5;241m=\u001b[39m load_model_from_config(\n\u001b[0;32m    540\u001b[0m     config,\n\u001b[0;32m    541\u001b[0m     vocab\u001b[38;5;241m=\u001b[39mvocab,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    545\u001b[0m     meta\u001b[38;5;241m=\u001b[39mmeta,\n\u001b[0;32m    546\u001b[0m )\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nlp\u001b[38;5;241m.\u001b[39mfrom_disk(model_path, exclude\u001b[38;5;241m=\u001b[39mexclude, overrides\u001b[38;5;241m=\u001b[39moverrides)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\util.py:714\u001b[0m, in \u001b[0;36mload_config\u001b[1;34m(path, overrides, interpolate)\u001b[0m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config_path\u001b[38;5;241m.\u001b[39mis_file():\n\u001b[1;32m--> 714\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE053\u001b[38;5;241m.\u001b[39mformat(path\u001b[38;5;241m=\u001b[39mconfig_path, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig file\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    715\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config\u001b[38;5;241m.\u001b[39mfrom_disk(\n\u001b[0;32m    716\u001b[0m         config_path, overrides\u001b[38;5;241m=\u001b[39moverrides, interpolate\u001b[38;5;241m=\u001b[39minterpolate\n\u001b[0;32m    717\u001b[0m     )\n",
      "\u001b[1;31mOSError\u001b[0m: [E053] Could not read config file from C:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\en_core_web_sm\\en_core_web_sm-2.2.0\\config.cfg"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# use displacy to visually show the entities. \n",
    "from spacy import displacy\n",
    "\n",
    "# load spacy model. Alternatively you can use en_core_web_lg\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# load the data\n",
    "df_movies = pd.read_csv('../data/imdb.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data inspection\n",
    "Take a look at the movie 'Lawrence of Arabia'. Which genres are connected with this movie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies[df_movies['Title'] == 'Lawrence of Arabia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the plot of the movie Lawrence of Arabia\n",
    "\n",
    "# code goes here\n",
    "\n",
    "# parse the text through Spacy NLP\n",
    "doc = nlp(plot)\n",
    "\n",
    "# render the text\n",
    "displacy.render(doc, style=\"ent\")\n",
    "\n",
    "# alternative output:\n",
    "# for ent in doc.ents:\n",
    "#   print (ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Compare the output\n",
    "Compare the output of Displacy with the tags associated with the movie. What do you notice? Would you include entities from Spacy to the metadata?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Process\n",
    "Now it is time to process everything. Create a new column `plot_entities` and process the items by applying the provided function below on the `Plot` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(x):\n",
    "  # there are some pesky NaN in the data. Easy but not so elegant way to fix this.\n",
    "  if pd.isna(x) == False:\n",
    "    doc = nlp(x)\n",
    "  else:\n",
    "    doc = ''\n",
    "  return doc\n",
    "  \n",
    "# code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Extract a specific entitity\n",
    "Now we are going to create a column `events` to extract EVENTS. Apply the provided function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_events(x):\n",
    "  events = []\n",
    "  if x != '':\n",
    "    for entities in x.ents:\n",
    "      if entities.label_ == 'EVENT':\n",
    "        events.append(entities.text)\n",
    "  return events\n",
    "\n",
    "# code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Inspect the results\n",
    "Now we have an extra column with a list of events it is time to count the events. A simple approach is to create a new dataframe where every row is an item of the list. Save the output to a CSV or other format to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observable is that an event such as _The Second World War_ is referred to in different ways: World War II or WWII. Time to clean up the data and create uniform concepts for events. Export the list from time to time to see the changes. You will notice that many movies are labelled as `war` but do not mention which war, so data cleaning is necessary. Use the function below to clean up the dataset iteratively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_entity(x, value, entities):\n",
    "  return [value if i in entities else i for i in x]  \n",
    "\n",
    "entities = ['WWII']\n",
    "value = 'World War II'\n",
    "\n",
    "df_movies['events'] = df_movies['events'].apply(lambda x: change_entity(x, value, entities))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create metadata\n",
    "Now you have a simple way to extract entities which in turn could serve as meta data it is time to create more columns. Which new columns can you think of? Take a look at [Extend Named Entity Recogniser (NER) to label new entities with spaCy](https://towardsdatascience.com/extend-named-entity-recogniser-ner-to-label-new-entities-with-spacy-339ee5979044) to see the different labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Finally\n",
    "Which similarity or clustering algorithm would you use in order to make use of the meta data?"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37c10f95d263926787ebf1d430d11186fc6b9bac835b8518e0b5006ed24f0c36"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
