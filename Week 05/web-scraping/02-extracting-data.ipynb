{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the URL\n",
    "import requests\n",
    "\n",
    "# to parse the HTMLDOM\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# patience is virtue\n",
    "import time\n",
    "import glob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the download file\n",
    "file = 'data/PBS/economy-france-threatens-new-rules-on-facebook-as-zuckerberg-visits.html'\n",
    "\n",
    "# parse the file\n",
    "soup = BeautifulSoup(open(file), 'html.parser')\n",
    "\n",
    "# get the title\n",
    "if soup.find('meta', property='og:title'):\n",
    "  title = soup.find('meta', property='og:title')['content']\n",
    "\n",
    "# get the description\n",
    "if soup.find('meta', property='og:description'):\n",
    "  description = soup.find('meta', property='og:description')['content']\n",
    "\n",
    "# article:published_time\n",
    "published_time = soup.find('meta', property='article:published_time')['content']\n",
    "\n",
    "# article:section\n",
    "section = soup.find('meta', property='article:section')['content']\n",
    "\n",
    "# article:tag\n",
    "tags = soup.find('meta', property='article:tag')['content']\n",
    "tags = tags.split(', ')\n",
    "\n",
    "# content\n",
    "content = soup.find(class_='body-text')\n",
    "\n",
    "# paragraphs\n",
    "paragraphs = content.find_all('p')\n",
    "\n",
    "body = []\n",
    "for p in paragraphs:\n",
    "  text = p.get_text()\n",
    "  if 'WATCH:' not in text:\n",
    "    body.append(text)\n",
    "\n",
    "data = {\n",
    "  'title': title,\n",
    "  'description': description,\n",
    "  'published_time': published_time,\n",
    "  'tags': tags,\n",
    "  'content': body\n",
    "}\n",
    "\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function from this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(file):\n",
    "  # the file\n",
    "  # file = 'data/wired/economy-france-threatens-new-rules-on-facebook-as-zuckerberg-visits.html'\n",
    "\n",
    "  # parse the file\n",
    "  soup = BeautifulSoup(open(file), 'html.parser')\n",
    "\n",
    "  # get the title\n",
    "  title = soup.find('meta', property='og:title')['content']\n",
    "\n",
    "  # I discussed this briefly during the presentation\n",
    "  # somethimes an element simply does not exist and will break code. You can use the solutions below to check.\n",
    "  # option 1 will result in more lines of code; but imo makes the code more comprehensible for others when working in projects\n",
    "\n",
    "  # option 1: check if it exists with a simple if statement and get the description\n",
    "  if soup.find('meta', property='og:description'):\n",
    "    description = soup.find('meta', property='og:description')['content']\n",
    "  else:\n",
    "    description = 'No description found'\n",
    "\n",
    "  # option 2: an one line if statement\n",
    "  description = soup.find('meta', property='og:description')['content'] if soup.find('meta', property='og:description') else 'No description found'\n",
    "  \n",
    "  # article:published_time\n",
    "  published_time = soup.find('meta', property='article:published_time')['content']\n",
    "\n",
    "  # article:section\n",
    "  section = soup.find('meta', property='article:section')['content']\n",
    "\n",
    "  # article:tag\n",
    "  tags = soup.find('meta', property='article:tag')['content']\n",
    "  tags = tags.split(', ')\n",
    "\n",
    "  # content\n",
    "  content = soup.find(class_='body-text')\n",
    "\n",
    "  # paragraphs\n",
    "  paragraphs = content.find_all('p')\n",
    "\n",
    "  body = []\n",
    "  for p in paragraphs:\n",
    "    text = p.get_text()\n",
    "    if 'WATCH:' not in text:\n",
    "      body.append(text)\n",
    "\n",
    "  data = {\n",
    "    'title': title,\n",
    "    'description': description,\n",
    "    'published_time': published_time,\n",
    "    'tags': tags,\n",
    "    'content': body\n",
    "  }\n",
    "\n",
    "  return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate through all the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load html files\n",
    "files = glob.glob('data/PBS/*.html')\n",
    "\n",
    "# iterate\n",
    "for file in files[1:30]:\n",
    "  data = extract(file)\n",
    "  print(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37c10f95d263926787ebf1d430d11186fc6b9bac835b8518e0b5006ed24f0c36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
